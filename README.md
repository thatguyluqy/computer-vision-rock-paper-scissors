# Computer Vision RPS
Through this project ill be using google's teachable machine tensor flow model to learn to detect hand positions of rock paper and scissors to be able to identify which pose the user is displaying. ill then create a python program that will randomly select one of these states and then challenge the user. the program will then compare the user input to the computers randomly selected position, and decide the outcome as a win, lose or draw based on the rules of rock paper scissors. 

the program will utilise machine learning via teachable machine and logic based code using python and fuse the two. so far i have created 4 states.

Rock - a collection of images with the hand gesture
Paper - a collection of images with the paper gesture
Scissors - a collection of immages with the scissors gesture
Nothing - a collection of images with no gesture.

ive then downloaded the model, and pushed them to my repository on github.